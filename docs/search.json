[
  {
    "objectID": "walkthrough.html",
    "href": "walkthrough.html",
    "title": "Running R code on MOGON II",
    "section": "",
    "text": "First some of the things I assume about you.\n\nYou can access the JGU HPC: MOGON II.\nYou’re working on windows. Some, but not all of this is transferable to other operating systems.\nYou’re adept at coding in R, but have limited to no experience writing bash scripts.\n\nAccess MOGON II via the terminal. On windows mobaxterm is a nice way to interface with the terminal (and is also the method recommended by the ZDV; download it free by following the hyperlink). Go through the login process (you’ll be used to two-factor authenticate) and you’re in!\nMOGON II’s resources are allocated via a slurm scheduler (I have no idea what slurm stands for…). Essentially, this allows us to share resources fairly with our colleagues. To check how our resource use is going, you can write sshare. The important metric is Fairshare; we have a certain amount of hypothetical resources allocated to our group, if we under use these fairshare will be &gt; 0.5, if we overuse them fairshare will be &lt; 0.5. Don’t worry too much if we’re over using this share, as it simply determines job priority with the rest of the community. Plus it reovers over time when we don’t run jobs. Perhaps more importantly, we’re still working out how much share we need. If we’re consistently over-using what I originally applied for, I’ll ask the ZDV for more.\nNext, you’ll see that you’re working in your local directory e.g. something like [tkeaney@login23 ~]$ will proceed any code you write on each line. This is a good place to test stuff, but not the directory we want to be working in when submitting real jobs to the slurm scheduler. Hanna’s group has a project called m2_hgu-tee which is our preferred directory to work within. To use this, ask me and I’ll add you as a user. Then, simply switch to that directory using the command cd /lustre/project/m2_jgu-tee. Here you can setup a folder specific to you, where you can save the R script you’d like to run, and direct any outputs into.\n\n\n\n\n\n\nBash command hint\n\n\n\ncd: changes the working directory."
  },
  {
    "objectID": "walkthrough.html#getting-started",
    "href": "walkthrough.html#getting-started",
    "title": "Running R code on MOGON II",
    "section": "",
    "text": "First some of the things I assume about you.\n\nYou can access the JGU HPC: MOGON II.\nYou’re working on windows. Some, but not all of this is transferable to other operating systems.\nYou’re adept at coding in R, but have limited to no experience writing bash scripts.\n\nAccess MOGON II via the terminal. On windows mobaxterm is a nice way to interface with the terminal (and is also the method recommended by the ZDV; download it free by following the hyperlink). Go through the login process (you’ll be used to two-factor authenticate) and you’re in!\nMOGON II’s resources are allocated via a slurm scheduler (I have no idea what slurm stands for…). Essentially, this allows us to share resources fairly with our colleagues. To check how our resource use is going, you can write sshare. The important metric is Fairshare; we have a certain amount of hypothetical resources allocated to our group, if we under use these fairshare will be &gt; 0.5, if we overuse them fairshare will be &lt; 0.5. Don’t worry too much if we’re over using this share, as it simply determines job priority with the rest of the community. Plus it reovers over time when we don’t run jobs. Perhaps more importantly, we’re still working out how much share we need. If we’re consistently over-using what I originally applied for, I’ll ask the ZDV for more.\nNext, you’ll see that you’re working in your local directory e.g. something like [tkeaney@login23 ~]$ will proceed any code you write on each line. This is a good place to test stuff, but not the directory we want to be working in when submitting real jobs to the slurm scheduler. Hanna’s group has a project called m2_hgu-tee which is our preferred directory to work within. To use this, ask me and I’ll add you as a user. Then, simply switch to that directory using the command cd /lustre/project/m2_jgu-tee. Here you can setup a folder specific to you, where you can save the R script you’d like to run, and direct any outputs into.\n\n\n\n\n\n\nBash command hint\n\n\n\ncd: changes the working directory."
  },
  {
    "objectID": "walkthrough.html#rslurm",
    "href": "walkthrough.html#rslurm",
    "title": "Running R code on MOGON II",
    "section": "rslurm",
    "text": "rslurm\nSeveral packages exist that are designed to run R code on slurm clusters. The ZDV recommends using the snow package. However, I find that the rslurm package offers a simpler solution and so the rest of this document shall be dedicated to its use.\n\n\nCode\nlibrary(rslurm)\nlibrary(tidyverse)\n\n\nMost of the content below is drawn from the packages online documentation or can be found in R via ?rslurm.\n\nA simple example\nFirst, lets get the HPC to do something very simple across a large parameter space.\nWe’ll build a test function that samples from a normal distribution many times with a mean and sd that we specify. The function then re-finds these summary statistics from the generated data.\n\n\nCode\ntest_function &lt;-\n  function(parameter_mean, parameter_sd){\n    sample &lt;- (rnorm(10^5, parameter_mean, parameter_sd))\n    c(sample_mean = mean(sample),\n      sample_sd = sd(sample))\n  }\n\n\nNow build the parameter space that we’ll iterate the function over\n\n\nCode\nparameters &lt;- expand_grid(parameter_mean = seq(from = 0, to = 10, by = 0.1),\n                          parameter_sd = seq(from = 0.1, to = 10, by = 0.1))\n\n#apply(parameters, test_function)"
  }
]